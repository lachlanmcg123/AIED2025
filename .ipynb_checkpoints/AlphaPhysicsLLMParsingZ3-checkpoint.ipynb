{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eb32caa3-8e4f-4a29-b026-48ddad44bacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sympy\n",
    "from sympy import symbols, Abs\n",
    "import re\n",
    "import ollama\n",
    "from typing import Dict, List, Tuple, Optional, Union\n",
    "import logging\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "import z3\n",
    "from z3 import Real, Solver, Implies, Not, If, Abs\n",
    "\n",
    "###70B parameter models\n",
    "#ollama run llama3.3\n",
    "#ollama run llama3.1:70b - this is lame\n",
    "#ollama run deepseek-r1:70b\n",
    "\n",
    "###14B Parameter Models\n",
    "#ollama run phi4:14b-fp16\n",
    "#ollama run deepseek-r1:14b-qwen-distill-fp16\n",
    "\n",
    "###14B Parameter Models 8-bit quantised\n",
    "#ollama run deepseek-r1:14b-qwen-distill-q8_0 \n",
    "#ollama run phi4:14b-q8_0\n",
    "\n",
    "#7B Parameter\n",
    "#ollama run mathstral:7b-v0.1-fp16\n",
    "#ollama run deepseek-r1:7b-qwen-distill-fp16\n",
    "\n",
    "#3B Parameter Models 16-bit quantised\n",
    "#ollama run llama3.2:3b-instruct-fp16\n",
    "#ollama run gemma2:2b-instruct-fp16\n",
    "\n",
    "#1B Parameter Models 16 bit quantised\n",
    "#ollama run llama3.2:1b-instruct-fp16\n",
    "#ollama run deepseek-r1:1.5b-qwen-distill-fp16\n",
    "\n",
    "###For Debugging\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.width', None)\n",
    "\n",
    "# Model configuration\n",
    "MODEL_ID_1 = \"Phi4\" #Phi4\n",
    "MODEL_ID_2 = \"None\" #None\n",
    "MODEL_IDS = [MODEL_ID_1, MODEL_ID_2]\n",
    "\n",
    "# Configuration variables\n",
    "FILE_DIRECTORY = r\"D:\\AI_Marking\\Datasets\\\"\n",
    "#Repalce above with actual directory\n",
    "ORIGINAL_FILE = os.path.join(FILE_DIRECTORY, r\"Filename.txt\")\n",
    "model_filename = \"_\".join(MODEL_IDS)\n",
    "model_filename = re.sub(r'[\\\\/:*?\"<>|]', '-', model_filename)\n",
    "PROCESSED_FILE = os.path.join(FILE_DIRECTORY, f\"QuestionNumberLLMmoduloZ3{model_filename}.txt\") #Change output filename as desired\n",
    "DICTIONARY_DIRECTORY = r\"D:\\AI_Marking\\Datasets\\Cache\"\n",
    "\n",
    "\n",
    "\n",
    "# Expected variables in student responses\n",
    "EXPECTED_VARIABLES = [\"v\", \"S\", \"w\", \"u\", \"t\"] #Ensure that the variable being solved for is the first entry in the list (if relevant)\n",
    "EXPECTED_VARIABLES_EXTENDED = [\"S\", \"u\", \"v\", \"w\", \"t\", \"t1\", \"t2\", \"t3\", \"ta\", \"tb\", \"x\", \"d\"] #A list that contains all variables that Z3 will accept (even if not requried)\n",
    "\n",
    "\n",
    "# Marker list for response parsing\n",
    "MARKER_LIST = [\n",
    "    \"List of Equations: \"\n",
    "]\n",
    "\n",
    "Default_Response = (\n",
    "    \"List of Equations: [] \"\n",
    ")\n",
    "\n",
    "# Column names for DataFrame\n",
    "def marker_to_base_name(marker: str) -> str:\n",
    "    #Convert the marker text into a usable column name (lowercase, underscores, etc.).\n",
    "    #E.g. \"List of Equations: \" -> \"list_of_equations\"\n",
    "    #     \"Student notes v-u limit: \" -> \"student_notes_v_u_limit\"\n",
    "    \n",
    "    # Remove trailing colon and extra spaces\n",
    "    text = marker.replace(\":\", \"\").strip()\n",
    "    # Replace hyphens with underscores first\n",
    "    text = text.replace(\"-\", \"_\")\n",
    "    # Replace spaces with underscores\n",
    "    text = text.replace(\" \", \"_\").lower()\n",
    "    return text\n",
    "base_column_names = [marker_to_base_name(m) for m in MARKER_LIST]\n",
    "\n",
    "COLUMN_NAMES = []\n",
    "for bc in base_column_names:\n",
    "    COLUMN_NAMES.append(f\"Model1_{bc}\")\n",
    "    COLUMN_NAMES.append(f\"Model2_{bc}\")\n",
    "\n",
    "MODEL_ERROR_COLUMNS = [\n",
    "    'Model1_Batch1_Fails',\n",
    "    'Model2_Batch2_Fails',\n",
    "    'Model1_Consensus_Fails',\n",
    "    'Model2_Consensus_Fails'\n",
    "]\n",
    "\n",
    "TIME_TRACKING_COLUMNS = [\n",
    "    'Model1_Raw_Time', 'Model2_Raw_Time',\n",
    "    'Model1_Batch1_Time', 'Model2_Batch2_Time',\n",
    "    'Consensus_Time',\n",
    "    'Total_Processing_Time'\n",
    "]\n",
    "\n",
    "TOKEN_TRACKING_COLUMNS = [\n",
    "        'Model1_Raw_Tokens', 'Model2_Raw_Tokens',\n",
    "        'Model1_Batch1_Tokens', 'Model2_Batch2_Tokens',\n",
    "        'Consensus_Tokens'\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0f210f-b851-4cbf-b424-91248bfad6cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "49442aff-ce5e-4a3f-ab82-0b8d3f78174f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining Class and Functions\n",
    "def sanitize_filename(filename):\n",
    "    # Replace characters that are invalid in Windows filenames\n",
    "    return re.sub(r'[\\\\/:*?\"<>|]', '-', filename)\n",
    "\n",
    "class LLMResponseValidator:\n",
    "    def __init__(self, max_repair_attempts: int = 3, verbose: bool = False):\n",
    "        #Initialize the validator with configuration settings.\n",
    "        #Args:\n",
    "        #    max_repair_attempts: Maximum number of repair attempts for parsing/consensus\n",
    "\n",
    "        self.model_ids = MODEL_IDS\n",
    "        self.max_repair_attempts = max_repair_attempts\n",
    "        self.verbose = verbose\n",
    "        self.variables = symbols(' '.join(EXPECTED_VARIABLES))\n",
    "        \n",
    "        # Error and attempt tracking\n",
    "        self.current_error = None  # Most recent error message\n",
    "        self.parse_error_count = 0  # Count of syntax/parsing errors\n",
    "        self.mismatch_error_count = 0  # Count of mathematical mismatches between models\n",
    "        self.current_attempt = 0  # Current attempt number for repair/consensus\n",
    "        self.error_history = {\n",
    "            'parse_errors': [],  # History of parsing errors\n",
    "            'mismatch_errors': []  # History of mathematical mismatch errors\n",
    "        }\n",
    "        self.model1_fails = 0\n",
    "        self.model2_fails = 0\n",
    "        self.model1_batch_time = 0\n",
    "        self.model2_batch_time = 0\n",
    "        self.model1_raw_time = 0.0\n",
    "        self.model2_raw_time = 0.0\n",
    "        self.consensus_time = 0\n",
    "        self.total_processing_time = 0\n",
    "\n",
    "        self.model1_raw_tokens = 0\n",
    "        self.model2_raw_tokens = 0\n",
    "        self.model1_batch1_tokens = 0\n",
    "        self.model2_batch2_tokens = 0\n",
    "        self.consensus_tokens = 0\n",
    "        \n",
    "        # Processing state\n",
    "        self.processing_state = {\n",
    "            'model1_response': None,\n",
    "            'model2_response': None,\n",
    "            'current_model': None,\n",
    "            'parsing_successful': False,\n",
    "            'math_match_successful': False\n",
    "        }\n",
    "        \n",
    "        # Set up logging (keep for debugging purposes)\n",
    "        logging.basicConfig(\n",
    "            level=logging.INFO,\n",
    "            format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "            filename='llm_validation.log'\n",
    "        )\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "        \n",
    "    def reset_state(self):\n",
    "        \"\"\"Reset all state tracking variables for new processing attempt\"\"\"\n",
    "        self.current_error = None\n",
    "        self.parse_error_count = 0\n",
    "        self.mismatch_error_count = 0\n",
    "        self.current_attempt = 0\n",
    "        self.error_history = {\n",
    "            'parse_errors': [],\n",
    "            'mismatch_errors': []\n",
    "        }\n",
    "        self.processing_state = {\n",
    "            'model1_response': None,\n",
    "            'model2_response': None,\n",
    "            'current_model': None,\n",
    "            'parsing_successful': False,\n",
    "            'math_match_successful': False\n",
    "        }\n",
    "\n",
    "    def convert_eq_to_z3(self, eq_str: str) -> str: \n",
    "        eq_str = eq_str.strip() #Note eq_str is meant to be Eq(lhs, rhs)\n",
    "        \n",
    "        # 1) remove trailing commas/semicolons\n",
    "        while eq_str.endswith(\",\") or eq_str.endswith(\";\"):\n",
    "            eq_str = eq_str[:-1].rstrip()\n",
    "        \n",
    "        # Handle Eq expressions\n",
    "        if eq_str.startswith(\"Eq(\"):\n",
    "            # Extract the content inside Eq(...)\n",
    "            inner_content = eq_str[3:-1] if eq_str.endswith(\")\") else eq_str[3:]\n",
    "            \n",
    "            # Split by the first comma that's not inside nested parentheses\n",
    "            paren_count = 0\n",
    "            comma_pos = -1\n",
    "            for i, char in enumerate(inner_content):\n",
    "                if char == '(':\n",
    "                    paren_count += 1\n",
    "                elif char == ')':\n",
    "                    paren_count -= 1\n",
    "                elif char == ',' and paren_count == 0:\n",
    "                    comma_pos = i\n",
    "                    break\n",
    "            \n",
    "            if comma_pos != -1:\n",
    "                lhs = inner_content[:comma_pos].strip()\n",
    "                rhs = inner_content[comma_pos+1:].strip()\n",
    "                \n",
    "                # Replace ^ with ** for exponentiation\n",
    "                lhs = lhs.replace(\"^\", \"**\")\n",
    "                rhs = rhs.replace(\"^\", \"**\")\n",
    "\n",
    "                ###Step5.1 This may cause issues. Let's see\n",
    "                lower_lhs = lhs.lower()\n",
    "                while 'abs(' in lower_lhs:\n",
    "                    start_idx = lower_lhs.find('abs(')\n",
    "            \n",
    "                    # Find matching closing parenthesis\n",
    "                    open_count = 1\n",
    "                    close_idx = start_idx + 4  # position after 'abs('\n",
    "                    while close_idx < len(lower_lhs) and open_count > 0:\n",
    "                        if lhs[close_idx] == '(':\n",
    "                            open_count += 1\n",
    "                        elif lhs[close_idx] == ')':\n",
    "                            open_count -= 1\n",
    "                        close_idx += 1\n",
    "            \n",
    "                    if open_count != 0:\n",
    "                        raise ValueError(f\"Mismatched parentheses in expression: {lhs}\")\n",
    "            \n",
    "                    # Extract inner expression (from original, not lowercase)\n",
    "                    inner_expr = lhs[start_idx + 4 : close_idx - 1].strip()\n",
    "            \n",
    "                    # Replace with If(...) in the original string (case preserved)\n",
    "                    replacement = f\"If({inner_expr} >= 0, {inner_expr}, -({inner_expr}))\"\n",
    "            \n",
    "                    lhs = lhs[:start_idx] + replacement + lhs[close_idx:]\n",
    "                    lower_lhs = lhs.lower()\n",
    "\n",
    "                lower_rhs = rhs.lower()\n",
    "                while 'abs(' in lower_rhs:\n",
    "                    start_idx = lower_rhs.find('abs(')\n",
    "            \n",
    "                    # Find matching closing parenthesis\n",
    "                    open_count = 1\n",
    "                    close_idx = start_idx + 4  # position after 'abs('\n",
    "                    while close_idx < len(lower_rhs) and open_count > 0:\n",
    "                        if rhs[close_idx] == '(':\n",
    "                            open_count += 1\n",
    "                        elif rhs[close_idx] == ')':\n",
    "                            open_count -= 1\n",
    "                        close_idx += 1\n",
    "            \n",
    "                    if open_count != 0:\n",
    "                        raise ValueError(f\"Mismatched parentheses in expression: {rhs}\")\n",
    "            \n",
    "                    # Extract inner expression (from original, not lowercase)\n",
    "                    inner_expr = rhs[start_idx + 4 : close_idx - 1].strip()\n",
    "            \n",
    "                    # Replace with If(...) in the original string (case preserved)\n",
    "                    replacement = f\"If({inner_expr} >= 0, {inner_expr}, -({inner_expr}))\"\n",
    "            \n",
    "                    rhs = rhs[:start_idx] + replacement + rhs[close_idx:]\n",
    "                    lower_rhs = rhs.lower()\n",
    "                \n",
    "                # Balance parentheses on both sides - this is the band-aid. So something must have gone wrong before here\n",
    "                if lhs.count('(') != lhs.count(')'):\n",
    "                    print(f\"Band-aid Bracket Solution Applied to LHS\")\n",
    "                    missing = lhs.count('(') - lhs.count(')')\n",
    "                    if missing > 0:\n",
    "                        lhs = lhs + (')'* missing)\n",
    "                    else:\n",
    "                        lhs = ('(' * abs(missing)) + lhs\n",
    "                        \n",
    "                if rhs.count('(') != rhs.count(')'):\n",
    "                    print(f\"Band-aid Bracket Solution Applied to RHS\")\n",
    "                    missing = rhs.count('(') - rhs.count(')')\n",
    "                    if missing > 0:\n",
    "                        rhs = rhs + (')'* missing)\n",
    "                    else:\n",
    "                        rhs = ('(' * abs(missing)) + rhs\n",
    "                \n",
    "                return f\"{lhs} == {rhs}\"\n",
    "            else:\n",
    "                # If we couldn't find a valid comma split, treat the whole thing as RHS\n",
    "                # with an empty LHS (this is probably an error case)\n",
    "                eq_str = eq_str.replace(\"^\", \"**\")\n",
    "                print(f\"Equation {eq_str=} does not have valid format with a LHS and a RHS\")\n",
    "                return eq_str\n",
    "        \n",
    "        # Handle non-Eq expressions\n",
    "        print(f\"An unexpected non-Eq expression was found. Either the model response is poor, or you should investigate.\")\n",
    "        eq_str = eq_str.replace(\"^\", \"**\")\n",
    "        if eq_str.count('(') != eq_str.count(')'):\n",
    "            missing = eq_str.count('(') - rhs.count(')')\n",
    "            if missing > 0:\n",
    "                eq_str = eq_str + (')'* missing)\n",
    "            else:\n",
    "                eq_str = ('(' * abs(missing)) + eq_str\n",
    "        return eq_str\n",
    "\n",
    "\n",
    "    def z3_string_to_sympy(self, z3_string: str) -> str:\n",
    "        \"\"\"\n",
    "        Convert a Z3-style string 'lhs == rhs' back into 'Eq(lhs, rhs)'.\n",
    "    \n",
    "        Example:\n",
    "            \"v == (w + 2)\" -> \"Eq(v, (w + 2))\"\n",
    "    \n",
    "        If the string doesn't contain '==', we just return it as-is\n",
    "        (no forced transformation).\n",
    "        \"\"\"\n",
    "        if '==' in z3_string:\n",
    "            parts = z3_string.split('==', 1)\n",
    "            lhs = parts[0].strip()\n",
    "            rhs = parts[1].strip()\n",
    "            return f\"Eq({lhs}, {rhs})\"\n",
    "        else:\n",
    "            return z3_string\n",
    "    \n",
    "    def z3_parse_equations(equation_list_str: str) -> Tuple[bool, dict]:\n",
    "        \"\"\"\n",
    "        Parse the given equation list with Z3, returning a success flag and details.\n",
    "        \"\"\"\n",
    "        # You might pass in the extended var list you want, or keep it a global\n",
    "        results = self.z3_parse_equation_list(equations_str, EXPECTED_VARIABLES_EXTENDED) ###Step 4.1 - I expected this function to be used, but instead we have eval() doing step 4\n",
    "\n",
    "        success = (len(results[\"errors\"]) == 0)\n",
    "        return success, results\n",
    "\n",
    "    \n",
    "    def equations_match(self, eq1: str, eq2: str) -> Tuple[bool, List[Tuple[int, int]]]:\n",
    "        #Check if two equation strings are mathematically equivalent.\n",
    "        #Returns:\n",
    "        #    Tuple[bool, List[Tuple[int, int]]]: \n",
    "        #        - Boolean indicating if all equations match\n",
    "        #        - List of matching equation indices (idx1, idx2)\n",
    "\n",
    "        parsed1 = self.parse_equation(eq1, \"Model1\")\n",
    "        parsed2 = self.parse_equation(eq2, \"Model2\")\n",
    "        \n",
    "        if parsed1 is None or parsed2 is None:\n",
    "            return False, []\n",
    "            \n",
    "        try:\n",
    "            # Convert single equations to lists for consistent handling\n",
    "            eqs1 = parsed1 if isinstance(parsed1, list) else [parsed1]\n",
    "            eqs2 = parsed2 if isinstance(parsed2, list) else [parsed2]\n",
    "            \n",
    "            # Keep track of which equations match\n",
    "            matches = []\n",
    "            used_indices = set()\n",
    "            \n",
    "            # Try to find matches for each equation in eqs1\n",
    "            for i, e1 in enumerate(eqs1):\n",
    "                for j, e2 in enumerate(eqs2):\n",
    "                    if j in used_indices:\n",
    "                        continue\n",
    "                        \n",
    "                    try:\n",
    "                        # Try direct comparison\n",
    "                        diff = sympy.simplify(e1 - e2)\n",
    "                        if diff == 0:\n",
    "                            matches.append((i, j))\n",
    "                            used_indices.add(j)\n",
    "                            break\n",
    "                    except Exception:\n",
    "                        # If we can't subtract, try string comparison\n",
    "                        if str(e1) == str(e2):\n",
    "                            matches.append((i, j))\n",
    "                            used_indices.add(j)\n",
    "                            break\n",
    "            \n",
    "            # Print debug info about matches\n",
    "            if self.verbose:\n",
    "                print(f\"\\nFound {len(matches)} matching equations:\")\n",
    "                for i, j in matches:\n",
    "                    print(f\"Equation {i} from first set matches equation {j} from second set\")\n",
    "                if len(matches) < max(len(eqs1), len(eqs2)):\n",
    "                    print(\"Some equations did not match:\")\n",
    "                    for i, e1 in enumerate(eqs1):\n",
    "                        if i not in [m[0] for m in matches]:\n",
    "                            print(f\"Unmatched from first set: {e1}\")\n",
    "                    for j, e2 in enumerate(eqs2):\n",
    "                        if j not in [m[1] for m in matches]:\n",
    "                            print(f\"Unmatched from second set: {e2}\")\n",
    "            \n",
    "            # All equations match if we found matches for all equations in both sets\n",
    "            all_match = (len(matches) == len(eqs1) == len(eqs2))\n",
    "            \n",
    "            return all_match, matches\n",
    "            \n",
    "        except Exception as e:\n",
    "            error_msg = f\"Error comparing equations: {str(e)}\"\n",
    "            self.mismatch_error_count += 1\n",
    "            self.error_history['mismatch_errors'].append(error_msg)\n",
    "            self.logger.error(error_msg)\n",
    "            self.processing_state['math_match_successful'] = False\n",
    "            return False\n",
    "\n",
    "    def create_repair_prompt(self, original_response: str, error_msg: str, \n",
    "                           student_answer: str) -> str:\n",
    "        #Create prompt for repairing invalid responses.\n",
    "        return f\"\"\"You are an expert in interpreting student mathematical responses and converting them into valid SymPy syntax. \n",
    "        Your overall goal is to extract all equations that students have explicitly written in their response to a physics question. \n",
    "        Note that equations described in words do not count, only record equations that students have written in SymPy syntax.\n",
    "        The student may have made syntactic errors, please use your expertise to interpret what the student meant and write record the syntactically correct version.\n",
    "        Ensure that only the expected variables are used, they are listed here: {EXPECTED_VARIABLES}\n",
    "\n",
    "        The student's answer is as follows: <<<{student_answer}>>>\n",
    "        Previously you recorded this equation: {original_response}\n",
    "        However it could not be parsed, giving this error: {error_msg}\n",
    "        \n",
    "        Your task is to repair your previous response which had a parsing error. Learn from the error messages, try changing symbols or operators to fit the required syntax and don't repeat the same error again. \n",
    "\n",
    "        Guidelines for your corrected response:\n",
    "        1. Begin with \"List of Equations: [\" and end with \"]\".\n",
    "        2. All equations must be in SymPy format using Eq(left, right), e.g., \"Eq(v, u + w)\" for \"v = u + w\"\n",
    "        3. If student writes expression without \"{EXPECTED_VARIABLES[0]}=\", assume that this is intended to be the right hand side of the equation and the left side would be {EXPECTED_VARIABLES[0]}\n",
    "        4. If multiple equations, separate them with commas\n",
    "        5. Only use these variables: {EXPECTED_VARIABLES}. Capitalisation of the variables is very important, please adjust the student's variables to match the capatilisation of the expected variables given here.\n",
    "        6. Correct notation errors (capitalization, brackets) but not mathematical errors\n",
    "        7. Use \"**(1/2)\" for square root\n",
    "        8. If there are multiple equations, separate them by commas but include all of them within \"[\" and \"]\". Do not use square brackets for any other purpose.\n",
    "        9. Example formats (pay careful attention to brackets and order of operations):\n",
    "           - Student writes \"v=2u+w\": Output should be \"Eq(v, (2*u) + w)\"\n",
    "           - Student writes \"v0=u^2/w\": Output should be \"Eq(v_0, (u**2)/w)\"\n",
    "           - Student writes \"u+w^2\": Output should be \"Eq(v, u + (w**2))\"\n",
    "        \n",
    "        Provide only the \"List of Equations: [...]\" response, with no explanation or justification.\n",
    "        \"\"\"\n",
    "\n",
    "    def create_consensus_prompt(self, student_answer: str, response1: str, \n",
    "                              response2: str, model1_id: str, model2_id: str) -> str:\n",
    "        #Create prompt for reaching consensus between different responses.\n",
    "        return f\"\"\"You are an expert in interpreting student mathematical responses and converting them into valid SymPy syntax.\n",
    "        \n",
    "        Two different interpretations were given for a student's answer, and we need your expert analysis to determine the most accurate interpretation.\n",
    "\n",
    "        Original student answer: <<<{student_answer}>>>\n",
    "        {model1_id} interpretation: {response1}\n",
    "        {model2_id} interpretation: {response2}\n",
    "\n",
    "        Guidelines for your consensus response:\n",
    "        1. Begin with \"List of Equations: [\". \n",
    "        2. Then write the equation(s) in the student response. \n",
    "        3. Finally end your response with \"]\".\n",
    "        \n",
    "        All equations must be in SymPy format using Eq(left, right).\n",
    "           - If student writes expression without \"{EXPECTED_VARIABLES[0]}=\", assume that this is intended to be the right hand side of the equation and the left side would be {EXPECTED_VARIABLES[0]}\n",
    "           - Separate multiple equations with commas\n",
    "           - Only use these variables: {EXPECTED_VARIABLES}. Capitalisation of the variables is very important, please adjust the student's variables to match the capatilisation of the expected variables given here.\n",
    "           - Correct notation (v0 → v_0, x^2 → x**2) but not math errors\n",
    "           - Use brackets for proper order of operations\n",
    "           - Use \"**(1/2)\" for square root\n",
    "           - If there are multiple equations, separate them by commas but include all of them within \"[\" and \"]\".\n",
    "           Examples:\n",
    "           - \"v=2u+w\" → \"Eq(v, (2*u) + w)\"\n",
    "           - \"v0=u^2/w\" → \"Eq(v_0, (u**2)/w)\" (Not subscripts should only be included if they are in the variables list)\n",
    "           - \"u+w^2\" → \"Eq(v, u + (w**2))\"\n",
    "\n",
    "        Analyze both interpretations and the original student answer, then provide your expert consensus in the exact format specified above. \n",
    "        Provide only the \"List of Equations: [...]\" response, with no explanation or justification.\n",
    "        \"\"\"\n",
    "\n",
    "    def build_initial_prompt(self, student_answer: str) -> str:\n",
    "        initial_prompt = f\"\"\"You are an expert in interpreting student mathematical responses to physics questions. Please read this student answer: <<<{student_answer}>>>\n",
    "\n",
    "        When writing equations, use SymPy syntax following these guidelines exactly:\n",
    "           - Use Eq(left, right) syntax, e.g., \"Eq(v, (2*u) + w)\"\n",
    "           - If student writes an expression without \"{EXPECTED_VARIABLES[0]}=\", assume that this is intended to be the right hand side of the equation and the left side would be {EXPECTED_VARIABLES[0]}\n",
    "           - Separate multiple equations with commas\n",
    "           - Only use these variables: {EXPECTED_VARIABLES}. Capitalisation of the variables is very important, please adjust the student's variables to match the capatilisation of the expected variables given here.\n",
    "           - Correct notation (for example v0 → v_0 or x^2 → x**2) but do not correct math errors\n",
    "           - Use brackets for proper order of operations\n",
    "           - Use \"**(1/2)\" for square root\n",
    "           - If there are multiple equations, separate them by commas but include all of them within \"[\" and \"]\".\n",
    "           Examples:\n",
    "           - \"v=2u+w\" → \"Eq(v, (2*u) + w)\"\n",
    "           - \"v0=u^2/w\" → \"Eq(v_0, (u**2)/w)\" (Not subscripts should only be included if they are in the variables list)\n",
    "           - \"u+w^2\" → \"Eq(v, u + (w**2))\"\n",
    "        \n",
    "        The based on these guidlines analyse the provided student answer and complete the following task exactly:\n",
    "        Write \"List of Equations: [\". Then write all equations that are contained in the student text using SymPy format following the guidelines above. Separate each equation with a comma (,). Then write \"]\".  If the student has not written an equation using symbols (only describing in words) then leave the list blank \"[]\".\n",
    "        \n",
    "        When completing the task, if the student writes any variables that are not in this list: {EXPECTED_VARIABLES} use your expert judgement to interpret and rewrite what they meant in terms of these variables.\n",
    "        Use the exact marker text and provide no additional text or justification.\n",
    "        \n",
    "        Student answer: <<<{student_answer}>>>\n",
    "        Your response to the task: \"\"\"\n",
    "        return initial_prompt\n",
    "\n",
    "    def extract_sections(self, text: str) -> Dict[str, str]:\n",
    "        #Extract sections from LLM response by finding text between markers.\n",
    "        #Returns a dictionary with snake_case keys and extracted values.\n",
    "        if pd.isna(text) or not text:\n",
    "            return {self._marker_to_key(marker): \"Error in Extraction\" \n",
    "                    for marker in MARKER_LIST}\n",
    "        \n",
    "        results = {}\n",
    "        \n",
    "        # Process each pair of consecutive markers\n",
    "        for i in range(len(MARKER_LIST)):\n",
    "            current_marker = MARKER_LIST[i]\n",
    "            next_marker = MARKER_LIST[i + 1] if i < len(MARKER_LIST) - 1 else None\n",
    "            \n",
    "            # Find start of current section\n",
    "            start_idx = text.find(current_marker)\n",
    "            if start_idx == -1:\n",
    "                # Marker not found\n",
    "                results[self._marker_to_key(current_marker)] = \"[]\" if i == 0 else \"0\"\n",
    "                continue\n",
    "                \n",
    "            # Move index to end of marker\n",
    "            start_idx += len(current_marker)\n",
    "            \n",
    "            # Find end of section (either next marker or end of text)\n",
    "            end_idx = text.find(next_marker) if next_marker else len(text)\n",
    "            if end_idx == -1:\n",
    "                end_idx = len(text)\n",
    "                \n",
    "            # Extract and clean the value\n",
    "            value = text[start_idx:end_idx].strip()\n",
    "            \n",
    "            # Store result\n",
    "            key = self._marker_to_key(current_marker)\n",
    "            if \"equations\" in key.lower() or \"equation\" in key.lower():\n",
    "                # Keep brackets for equations (both list_of_equations and final_equation)\n",
    "                results[key] = value if value else \"[]\"\n",
    "            else:\n",
    "                # For other markers, just get the first digit or default to 0\n",
    "                results[key] = next((char for char in value if char.isdigit()), \"0\")\n",
    "        \n",
    "        if self.verbose:\n",
    "            print(\"\\nExtracted results:\")\n",
    "            for k, v in results.items():\n",
    "                print(f\"{k}: {v}\")\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def _marker_to_key(self, marker: str) -> str:\n",
    "        \"\"\"Convert a marker to a snake_case dictionary key.\"\"\"\n",
    "        # Remove the trailing ': ' and convert to lowercase\n",
    "        key = marker.rstrip(': ').lower()\n",
    "        # Replace hyphens with underscores\n",
    "        key = key.replace('-', '_')\n",
    "        # Replace spaces with underscores and remove special characters\n",
    "        key = re.sub(r'[^a-z0-9_\\s]', '', key)\n",
    "        key = re.sub(r'\\s+', '_', key)\n",
    "        return key\n",
    "        \n",
    "    \n",
    "    def get_llm_response(self, model_id: str, prompt: str) -> tuple[str, int]:\n",
    "        \"\"\"Get response from LLM model.\"\"\"\n",
    "\n",
    "        if self.verbose:\n",
    "            print(f\"\\nCalling {model_id}...\")\n",
    "            \n",
    "        try:\n",
    "            response = ollama.chat(\n",
    "                model=model_id,\n",
    "                messages=[{'role': 'user', 'content': prompt}],\n",
    "                options={\"temperature\": 0.0, \"num_predict\": 1500}\n",
    "            )\n",
    "            return response['message']['content'], response['eval_count']\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error getting response from {model_id}: {str(e)}\")\n",
    "            return \"\", 0\n",
    "\n",
    "\n",
    "    def reach_consensus(self, student_answer: str, equations1: str, equations2: str, \n",
    "                   df: pd.DataFrame, idx: int) -> str:\n",
    "        #Attempt to reach consensus between two model responses.\n",
    "        #Args:\n",
    "        #    student_answer: Original student answer\n",
    "        #    equations1: First model's equation response\n",
    "        #    equations2: Second model's equation response\n",
    "        #    df: DataFrame for storing results\n",
    "        #    idx: Row index in DataFrame\n",
    "        #Returns:\n",
    "        #    str: Consensus equation or appropriate fallback\n",
    "        # Step 0: Check initial parsing of both models' equations\n",
    "        current_eq1, parsed1 = self.attempt_parse(equations1)\n",
    "        current_eq2, parsed2 = self.attempt_parse(equations2)\n",
    "        #######Check, this step may be unnecessary as we are pretty sure that if it is going to successfully repair that it would have already.\n",
    "        #######We do however want the parsed1 and parsed2 variables.\n",
    "        #######Also we definitely do not want to run this before even checking if the equations are the same. This is a huge un-needed cost.\n",
    "        #####18/2/25 - introduced the new function. Note that it has many unnecessary arguments that I should remove\n",
    "        \n",
    "        # If only one parses, return that one\n",
    "        if parsed1 is not None and parsed2 is None:\n",
    "            return current_eq1\n",
    "        elif parsed2 is not None and parsed1 is None:\n",
    "            return current_eq2\n",
    "            \n",
    "        consensus_attempts = 0\n",
    "        max_consensus_attempts = 2  # Two attempts after initial\n",
    "        \n",
    "        while consensus_attempts <= max_consensus_attempts:\n",
    "            # Step 2: Check if current equations match\n",
    "            if parsed1 is not None and parsed2 is not None:\n",
    "                all_match, _ = self.equations_match(current_eq1, current_eq2)\n",
    "                if all_match:\n",
    "                    return current_eq1\n",
    "            \n",
    "            # Step 1: Check if we've exceeded max attempts\n",
    "            if consensus_attempts >= max_consensus_attempts:\n",
    "                if parsed1 is not None:\n",
    "                    return current_eq1\n",
    "                elif parsed2 is not None:\n",
    "                    return current_eq2\n",
    "                else:\n",
    "                    return \"Error: Unable to reach consensus and no valid equations available\"\n",
    "            \n",
    "            consensus_attempts += 1\n",
    "            self.logger.info(f\"Starting consensus attempt {consensus_attempts}\")\n",
    "            \n",
    "            # Steps 3-4: Get and check Model1's consensus response\n",
    "            consensus_prompt = self.create_consensus_prompt(\n",
    "                student_answer,\n",
    "                current_eq1,\n",
    "                current_eq2,\n",
    "                self.model_ids[0],\n",
    "                self.model_ids[1]\n",
    "            )\n",
    "            \n",
    "            new_eq1, tokens = self.get_llm_response(self.model_ids[0], consensus_prompt)\n",
    "            self.consensus_tokens += tokens\n",
    "            df.at[idx, 'Consensus_Tokens'] = self.consensus_tokens\n",
    "            new_eq1, parsed1 = self.attempt_parse_and_repair(\n",
    "                new_eq1, student_answer, self.model_ids[0], df, idx, \"Model1\", in_consensus_mode=True\n",
    "            )\n",
    "            if parsed1 is not None:\n",
    "                current_eq1 = new_eq1\n",
    "            \n",
    "            # Steps 5-6: Get and check Model2's consensus response\n",
    "            consensus_prompt = self.create_consensus_prompt(\n",
    "                student_answer,\n",
    "                current_eq1,\n",
    "                current_eq2,\n",
    "                self.model_ids[1],\n",
    "                self.model_ids[0]\n",
    "            )\n",
    "            \n",
    "            new_eq2, tokens = self.get_llm_response(self.model_ids[1], consensus_prompt)\n",
    "            self.consensus_tokens += tokens\n",
    "            df.at[idx, 'Consensus_Tokens'] = self.consensus_tokens\n",
    "            new_eq2, parsed2 = self.attempt_parse_and_repair(\n",
    "                new_eq2, student_answer, self.model_ids[1], df, idx, \"Model2\", in_consensus_mode=True\n",
    "            )\n",
    "            if parsed2 is not None:\n",
    "                current_eq2 = new_eq2\n",
    "                \n",
    "            # Step 7: If only one response parses, return it\n",
    "            if parsed1 is not None and parsed2 is None:\n",
    "                self.logger.info(\"Only Model1 response parsed successfully\")\n",
    "                return current_eq1\n",
    "            elif parsed2 is not None and parsed1 is None:\n",
    "                self.logger.info(\"Only Model2 response parsed successfully\")\n",
    "                return current_eq2\n",
    "                \n",
    "            self.logger.info(f\"Completed consensus attempt {consensus_attempts}\")\n",
    "            # Loop continues to check for matches if both parse\n",
    "            \n",
    "        # This should never be reached due to the checks in the loop\n",
    "        return \"Error: Unexpected end of consensus process\"\n",
    "    \n",
    "    def extract_bracket_content(self, response) -> str:\n",
    "        if not response:\n",
    "            return \"\"\n",
    "        pattern = r'\\[(.*?)\\]'  # non-greedy match of anything between [ and ]\n",
    "        match = re.search(pattern, str(response), re.DOTALL)\n",
    "        if match:\n",
    "            return match.group(1).strip()\n",
    "        return \"\"\n",
    "\n",
    "    def store_extracted_sections_in_df(self, df: pd.DataFrame, row_idx: int, model_label: str, \n",
    "                                  response_text: str, repairing_equations: bool = False, in_consensus_mode: bool = False):\n",
    "        #Stores extracted sections in the DataFrame.\n",
    "        #Args:\n",
    "        #    df: DataFrame to update\n",
    "        #    row_idx: Index of row to update\n",
    "        #    model_label: Label of model (e.g., \"Model1\" or \"Model2\")\n",
    "        #    response_text: Text response to extract sections from\n",
    "        #    repairing_equations: If True, only update equations column\n",
    "        sections_dict = self.extract_sections(response_text)\n",
    "    \n",
    "        for base_col_name, content in sections_dict.items():\n",
    "            # Skip non-equation columns if we're only repairing equations\n",
    "            if repairing_equations and \"equations\" not in base_col_name:\n",
    "                continue\n",
    "                \n",
    "            # Strip any existing model prefixes before adding the new one\n",
    "            clean_base_name = base_col_name\n",
    "            for prefix in ['Model1_', 'Model2_']:\n",
    "                if clean_base_name.startswith(prefix):\n",
    "                    clean_base_name = clean_base_name[len(prefix):]\n",
    "        \n",
    "            # Build final DF column name\n",
    "            final_col_name = f\"{model_label}_{clean_base_name}\"\n",
    "\n",
    "        \n",
    "            if \"equations\" in base_col_name:\n",
    "                # This is the line for the bracket content, e.g. \"list_of_equations\"\n",
    "                bracket_content = self.extract_bracket_content(content)\n",
    "                # Store with the enclosing brackets\n",
    "                if not in_consensus_mode:#in_consensus_mode:\n",
    "                    df.at[row_idx, final_col_name] = f\"[{bracket_content}]\"\n",
    "    \n",
    "            else:\n",
    "                # Attempt to convert \"1\"/\"0\" to int, else store string\n",
    "                try:\n",
    "                    df.at[row_idx, final_col_name] = int(content)\n",
    "                except ValueError:\n",
    "                    df.at[row_idx, final_col_name] = content\n",
    "        return df\n",
    "\n",
    "\n",
    "    def attempt_parse_and_repair(self, equations_str: str, student_answer: str, model_id: str, df: pd.DataFrame, idx: int, model_label: str, in_consensus_mode: bool = False) -> Tuple[str, Optional[List[str]]]:\n",
    "        \"\"\"\n",
    "        Z3-based attempt to parse a list of equations in Sympy format:\n",
    "            e.g. \"[Eq(v, w), Eq(x, S^2)]\"\n",
    "        If it fails, gather detailed error messages, ask the model to repair.\n",
    "        On success, we store the final eq string (Sympy format) back to the DataFrame.\n",
    "    \n",
    "        Args:\n",
    "            equations_str (str): e.g. \"[Eq(v, w), Eq(x, y^2)]\"\n",
    "            student_answer (str): The original student's text, used for repair prompts\n",
    "            model_id (str): ID of the LLM model\n",
    "            df (pd.DataFrame): The main DataFrame to store results\n",
    "            idx (int): Row index in DataFrame\n",
    "            model_label (str): \"Model1\" or \"Model2\"\n",
    "            in_consensus_mode (bool): If True, we might skip storing some columns\n",
    "    \n",
    "        Returns:\n",
    "            (final_equations, list_of_parsed_z3_strings_or_None)\n",
    "            Example:\n",
    "              (\"[Eq(v, w), Eq(x, y^2)]\", [\"v == w\", \"x == y**2\"])\n",
    "            If we fail entirely, we might return (\"[Eq(v, w), ...]\", None).\n",
    "        \"\"\"\n",
    "        #### 1) Try Z3 parse\n",
    "        parse_results = self.z3_parse_equation_list(equations_str, EXPECTED_VARIABLES_EXTENDED) ###Step 2 - Parse Equation list\n",
    "\n",
    "        z3_parsed = parse_results[\"parsed_equations\"]\n",
    "        error_dict = parse_results[\"errors\"]\n",
    "\n",
    "        if error_dict:\n",
    "            # Means we had parse errors\n",
    "            if model_label == \"Model1\":\n",
    "                self.model1_fails += 1\n",
    "            else:\n",
    "                self.model2_fails += 1\n",
    "    \n",
    "        if not error_dict:\n",
    "            # SUCCESS => we re-convert z3_parsed back to \"Eq(...)\" form\n",
    "            # We'll store them in a bracketed list => \"[Eq(...), Eq(...)]\"\n",
    "            sympy_equations = []\n",
    "            for z3_str in z3_parsed:\n",
    "                sympy_equations.append(self.z3_string_to_sympy(z3_str))\n",
    "    \n",
    "            # Build final string\n",
    "            final_equations_str = \"[\" + \", \".join(sympy_equations) + \"]\"\n",
    "    \n",
    "            # Store in the DataFrame (unless in_consensus_mode, you might not update all columns)\n",
    "            df.at[idx, f\"{model_label}_list_of_equations\"] = final_equations_str\n",
    "    \n",
    "            # Return success\n",
    "            return final_equations_str, z3_parsed\n",
    "    \n",
    "        #### 2) If we get here, we have parse errors\n",
    "        # Consolidate them into a single string\n",
    "        # Example:\n",
    "        # \"NameError: name 's' is not defined\" -> eq: \"v == (s + w)\"\n",
    "        # \"SyntaxError: mismatched parenthesis\" -> eq: \"x == (S^2))\"\n",
    "        error_messages = []\n",
    "        for err_msg, eq_list in error_dict.items():\n",
    "            # Filter out None values and convert all items to strings\n",
    "            valid_eqs = [str(eq) for eq in eq_list if eq is not None]\n",
    "            if valid_eqs:  # Only proceed if we have valid equations\n",
    "                eq_list_str = \"; \".join(valid_eqs)\n",
    "                error_messages.append(\n",
    "                    f\"Equations: {eq_list_str}\\nError: {err_msg}\\n\"\n",
    "                )\n",
    "        final_error_msg = \"\\n\".join(error_messages)\n",
    "        print(f\"Errors found. Here are the messages {final_error_msg=}\")\n",
    "    \n",
    "        # Now we call create_repair_prompt with that detailed info\n",
    "        repair_prompt = self.create_repair_prompt(\n",
    "            original_response=equations_str,\n",
    "            error_msg=final_error_msg,\n",
    "            student_answer=student_answer\n",
    "        )\n",
    "    \n",
    "        # Let the LLM attempt a repair up to N times\n",
    "        repair_attempts = self.max_repair_attempts\n",
    "        attempt_count = 0\n",
    "        repaired_equations_str = equations_str  # start as the original\n",
    "        \n",
    "        error_messages_2 = []\n",
    "        error_messages_2.append(final_error_msg)\n",
    "        while attempt_count < repair_attempts:\n",
    "            attempt_count += 1\n",
    "            try:\n",
    "                repair_response, repair_tokens = self.get_llm_response(model_id, repair_prompt)\n",
    "            except Exception as e:\n",
    "                # If the LLM call fails, we can't do anything else\n",
    "                print(f\"LLM call failed: {str(e)}\")\n",
    "                return repaired_equations_str, None\n",
    "    \n",
    "            # Track tokens, fails, etc. if needed\n",
    "            if model_label == \"Model1\":\n",
    "                self.model1_batch1_tokens += repair_tokens\n",
    "            else:\n",
    "                self.model2_batch2_tokens += repair_tokens\n",
    "    \n",
    "            # We'll store the repaired text in the DataFrame (equations only)\n",
    "            self.store_extracted_sections_in_df(\n",
    "                df, idx, model_label, repair_response,\n",
    "                repairing_equations=True,\n",
    "                in_consensus_mode=in_consensus_mode\n",
    "            )\n",
    "    \n",
    "            # Pull out the newly repaired eq string\n",
    "            repaired_equations_str = df.at[idx, f\"{model_label}_list_of_equations\"]\n",
    "    \n",
    "            # Try parsing again\n",
    "            parse_results_2 = self.z3_parse_equation_list(repaired_equations_str, EXPECTED_VARIABLES_EXTENDED) ###Just Changed this line 1035pm 6/3/25 to act on the repaired_equations_str\n",
    "\n",
    "            z3_parsed_2 = parse_results_2[\"parsed_equations\"]\n",
    "            error_dict_2 = parse_results_2[\"errors\"]\n",
    "    \n",
    "            if not error_dict_2:\n",
    "                # SUCCESS after repair\n",
    "                # Convert them back to \"Eq(...)\" to store\n",
    "                sympy_equations = []\n",
    "                for z3_str in z3_parsed_2:\n",
    "                    sympy_equations.append(self.z3_string_to_sympy(z3_str))\n",
    "    \n",
    "                final_equations_str = \"[\" + \", \".join(sympy_equations) + \"]\"\n",
    "                df.at[idx, f\"{model_label}_list_of_equations\"] = final_equations_str\n",
    "                return final_equations_str, z3_parsed_2\n",
    "            else:\n",
    "                # Update repair_prompt with new parse errors\n",
    "                #error_messages_2 = []\n",
    "                for err_msg, eq_list in error_dict_2.items():\n",
    "                    eq_list_str = \"; \".join(eq_list)\n",
    "                    error_messages_2.append(f\"Equations: {eq_list_str}\\nError: {err_msg}\\n\")\n",
    "                final_error_msg_2 = \"\\n\".join(error_messages_2)\n",
    "\n",
    "                print(f\"After repair errors still found. Here are the messages {final_error_msg_2=}\")\n",
    "                # Rebuild the repair prompt\n",
    "                repair_prompt = self.create_repair_prompt(\n",
    "                    original_response=repaired_equations_str,\n",
    "                    error_msg=final_error_msg_2,\n",
    "                    student_answer=student_answer\n",
    "                )\n",
    "    \n",
    "        # If we exhaust attempts, return what we have (likely None)\n",
    "        return repaired_equations_str, None\n",
    "\n",
    "\n",
    "    def attempt_parse(self, equations_str: str) -> Tuple[str, Optional[Union[sympy.Expr, List[sympy.Expr]]]]:\n",
    "        parsed_expr = self.parse_equation(equations_str, \"Consensus Check\")   \n",
    "        return equations_str, parsed_expr\n",
    "\n",
    "    \n",
    "    def load_or_create_cache(self, model_id):\n",
    "        cache_dir = DICTIONARY_DIRECTORY  # Directory to store cache files\n",
    "        os.makedirs(cache_dir, exist_ok=True)\n",
    "        \n",
    "        # Sanitize model_id before using in filename\n",
    "        safe_model_id = sanitize_filename(model_id)\n",
    "        cache_file = os.path.join(cache_dir, f\"response_cache_{safe_model_id}.json\")\n",
    "        \n",
    "        if os.path.exists(cache_file):\n",
    "            try:\n",
    "                with open(cache_file, 'r') as f:\n",
    "                    return json.load(f)\n",
    "            except (json.JSONDecodeError, IOError) as e:\n",
    "                self.logger.error(f\"Error loading cache for {model_id}: {str(e)}\")\n",
    "                return {}\n",
    "        return {}\n",
    "    \n",
    "    def save_cache(self, cache_dict, model_id):\n",
    "        cache_dir = DICTIONARY_DIRECTORY\n",
    "        \n",
    "        # Sanitize model_id before using in filename\n",
    "        safe_model_id = sanitize_filename(model_id)\n",
    "        cache_file = os.path.join(cache_dir, f\"response_cache_{safe_model_id}.json\")\n",
    "        \n",
    "        try:\n",
    "            with open(cache_file, 'w') as f:\n",
    "                json.dump(cache_dict, f)\n",
    "        except IOError as e:\n",
    "            self.logger.error(f\"Error saving cache for {model_id}: {str(e)}\")\n",
    "    \n",
    "    def load_consensus_cache(self, filename):\n",
    "        cache_dir = DICTIONARY_DIRECTORY\n",
    "        os.makedirs(cache_dir, exist_ok=True)\n",
    "        \n",
    "        # Sanitize filename before using\n",
    "        safe_filename = sanitize_filename(filename)\n",
    "        cache_file = os.path.join(cache_dir, safe_filename)\n",
    "        \n",
    "        if os.path.exists(cache_file):\n",
    "            try:\n",
    "                with open(cache_file, 'r') as f:\n",
    "                    return json.load(f)\n",
    "            except (json.JSONDecodeError, IOError) as e:\n",
    "                self.logger.error(f\"Error loading consensus cache: {str(e)}\")\n",
    "                return {}\n",
    "        return {}\n",
    "    \n",
    "    def save_consensus_cache(self, cache_dict, filename):\n",
    "        cache_dir = DICTIONARY_DIRECTORY\n",
    "        \n",
    "        # Sanitize filename before using\n",
    "        safe_filename = sanitize_filename(filename)\n",
    "        cache_file = os.path.join(cache_dir, safe_filename)\n",
    "        \n",
    "        try:\n",
    "            with open(cache_file, 'w') as f:\n",
    "                json.dump(cache_dict, f)\n",
    "        except IOError as e:\n",
    "            self.logger.error(f\"Error saving consensus cache: {str(e)}\")\n",
    "\n",
    "\n",
    "    def z3_parse_equation_list(self, equation_list_str: str, extended_vars=EXPECTED_VARIABLES_EXTENDED, var_dict=None) -> dict:\n",
    "        # Quick check for empty or \"[]\" string\n",
    "        if not equation_list_str or equation_list_str.strip() in (\"[]\", \"\"):\n",
    "            return {\n",
    "                \"parsed_equations\": [],\n",
    "                \"errors\": {}\n",
    "            }\n",
    "        \n",
    "        # Normalize all whitespace first\n",
    "        eq_str = equation_list_str.replace('\\n', ' ')  # Replace newlines with spaces\n",
    "        #eq_str = ' '.join(eq_str.split())  # Normalize all whitespace to single spaces\n",
    "        #eq_str = eq_str.strip()  # Remove leading/trailing whitespace\n",
    "        \n",
    "        # Remove outer brackets if present\n",
    "        if eq_str.startswith(\"[\"):\n",
    "            eq_str = eq_str[1:]\n",
    "        if eq_str.endswith(\"]\"):\n",
    "            eq_str = eq_str[:-1]\n",
    "        eq_str = eq_str.strip()\n",
    "    \n",
    "        # Initialize variables for Z3\n",
    "        if var_dict is None:\n",
    "            var_dict = {v: z3.Real(v) for v in extended_vars}\n",
    "            var_dict[\"Abs\"] = z3.Abs\n",
    "            var_dict[\"If\"] = z3.If\n",
    "            var_dict[\"sqrt\"] = z3.Sqrt\n",
    "        \n",
    "        # First, normalize ALL comma+Eq variations (including any whitespace) to a standard format\n",
    "        # This regex matches a comma followed by any whitespace (including none) and then \"Eq\"\n",
    "        normalized = re.sub(r',\\s*Eq', ', Eq', eq_str)\n",
    "        \n",
    "        # Normalize comma+Eq variations first\n",
    "        normalized = normalized.replace(',Eq', ', Eq')  # Force a space after comma\n",
    "        normalized = re.sub(r',\\s*Eq', ', Eq', normalized)  # Catch any other variations\n",
    "        \n",
    "        # Then split and reconstruct\n",
    "        raw_pieces = []\n",
    "        if \"Eq(\" in normalized:\n",
    "            splitted = normalized.split(', Eq(')\n",
    "            for i, piece in enumerate(splitted):\n",
    "                piece = piece.strip()\n",
    "                if i == 0:\n",
    "                    raw_pieces.append(piece)\n",
    "                else:\n",
    "                    raw_pieces.append(\"Eq(\" + piece) ###Step 2.1 Maybe Error - Does this add in an unwanted Bracket?\n",
    "        else:\n",
    "            raw_pieces = [normalized]\n",
    "        \n",
    "        parsed_equations = []\n",
    "        error_dict = {}\n",
    "        \n",
    "        for piece in raw_pieces:\n",
    "            piece = piece.strip()\n",
    "            # Convert from Sympy format -> Z3 string\n",
    "            z3_str = self.convert_eq_to_z3(piece) ###Step 3 - Parse equations and get back a Z3 string\n",
    "            # Try to eval in a Z3 environment\n",
    "            try:\n",
    "                expr = eval(z3_str, {}, var_dict) #Step 4 - I guess that this line checks if the Z3 equation can be evaluated as true or false\n",
    "                # If we reached here, we have a valid Z3 expression\n",
    "                parsed_equations.append(z3_str) \n",
    "            except Exception as e:\n",
    "                err_msg = f\"{type(e).__name__}: {str(e)}\"\n",
    "                if err_msg not in error_dict:\n",
    "                    error_dict[err_msg] = []\n",
    "                error_dict[err_msg].append(z3_str)\n",
    "        \n",
    "        return {\"parsed_equations\": parsed_equations, \"errors\": error_dict}\n",
    "\n",
    "\n",
    "    \n",
    "    def process_dataframe_in_batches(self, test: bool = False, do_consensus: bool = False): \n",
    "        #Process all rows in multiple steps/batches to avoid repeated reloading of models.\n",
    "        #Saves partial progress to PROCESSED_FILE after each row to allow resuming.\n",
    "\n",
    "        # -----------------------------------------------------------------\n",
    "        # 1. Load or create DataFrame\n",
    "        # -----------------------------------------------------------------\n",
    "        if os.path.exists(PROCESSED_FILE):\n",
    "            if self.verbose:\n",
    "                print(f\"\\nLoading existing processed file: {PROCESSED_FILE}\")\n",
    "            df = pd.read_csv(PROCESSED_FILE, sep='\\t', encoding='latin-1')\n",
    "        else:\n",
    "            if self.verbose:\n",
    "                print(f\"\\nStarting new processing from: {ORIGINAL_FILE}\")\n",
    "            df = pd.read_csv(ORIGINAL_FILE, sep='\\t', encoding='latin-1')\n",
    "        \n",
    "        #model1_cache = self.load_or_create_cache(self.model_ids[0])\n",
    "        #model2_cache = self.load_or_create_cache(self.model_ids[1])\n",
    "        \n",
    "        # Read last recorded error counts\n",
    "        if os.path.exists(PROCESSED_FILE):\n",
    "            last_row_with_counts = df.loc[df['Model1_Batch1_Fails'].notna() | \n",
    "                                          df['Model2_Batch2_Fails'].notna() | \n",
    "                                          df['Model1_Consensus_Fails'].notna() | \n",
    "                                          df['Model2_Consensus_Fails'].notna()]\n",
    "            \n",
    "            if not last_row_with_counts.empty:\n",
    "                last_idx = last_row_with_counts.index.max()\n",
    "                model1_fails_val = df.at[last_idx, 'Model1_Batch1_Fails']\n",
    "                model2_fails_val = df.at[last_idx, 'Model2_Batch2_Fails']\n",
    "                \n",
    "                self.model1_fails = int(model1_fails_val) if pd.notna(model1_fails_val) else 0\n",
    "                self.model2_fails = int(model2_fails_val) if pd.notna(model2_fails_val) else 0\n",
    "\n",
    "                \n",
    "                if self.verbose:\n",
    "                    print(f\"Resuming with Model1 fails: {self.model1_fails}, Model2 fails: {self.model2_fails}\")\n",
    "            else:\n",
    "                self.model1_fails = 0\n",
    "                self.model2_fails = 0\n",
    "        else:\n",
    "            self.model1_fails = 0\n",
    "            self.model2_fails = 0\n",
    "\n",
    "\n",
    "        # Read last recorded time values\n",
    "        if os.path.exists(PROCESSED_FILE):\n",
    "            last_row_with_times = df.loc[df['Total_Processing_Time'].notna()]\n",
    "            \n",
    "            if not last_row_with_times.empty:\n",
    "                last_idx = last_row_with_times.index.max()\n",
    "                print(f\"Finding Last index\")\n",
    "                while (last_idx in df.index and (pd.isna(df.at[last_idx, 'Model2_Batch2_Time']) or df.at[last_idx, 'Model2_Batch2_Time'] == 0.0)):\n",
    "                    last_idx -= 1\n",
    "                print(f\"Last index is  {last_idx=}\")\n",
    "                if last_idx < 0:\n",
    "                    # This means we never found a row with good data \n",
    "                    # (or we subtracted too far). \n",
    "                    # So skip the reading or set to defaults:\n",
    "                    m1_time = 0.0\n",
    "                    m2_time = 0.0\n",
    "                    cons_time = 0.0\n",
    "                    total_time = 0.0\n",
    "                    last_idx = 0\n",
    "                    print(\"did a reset\")\n",
    "                else:\n",
    "                    # We can safely do the lookups\n",
    "                    m1_time = df.at[last_idx, 'Model1_Batch1_Time']\n",
    "                    m2_time = df.at[last_idx, 'Model2_Batch2_Time']\n",
    "                    cons_time = df.at[last_idx, 'Consensus_Time']\n",
    "                    total_time = df.at[last_idx, 'Total_Processing_Time']\n",
    "                \n",
    "                r1_time = df.at[last_idx, 'Model1_Raw_Time']\n",
    "                if pd.notna(r1_time):\n",
    "                    self.model1_raw_time = float(r1_time)\n",
    "                \n",
    "                r2_time = df.at[last_idx, 'Model2_Raw_Time']\n",
    "                if pd.notna(r2_time):\n",
    "                    self.model2_raw_time = float(r2_time)\n",
    "                \n",
    "                self.model1_batch_time = float(m1_time) if pd.notna(m1_time) else 0.0\n",
    "                self.model2_batch_time = float(m2_time) if pd.notna(m2_time) else 0.0\n",
    "                self.consensus_time = float(cons_time) if pd.notna(cons_time) else 0.0\n",
    "                self.total_processing_time = float(total_time) if pd.notna(total_time) else 0.0\n",
    "\n",
    "                r1_raw = df.at[last_idx, 'Model1_Raw_Tokens']\n",
    "                if pd.notna(r1_raw):\n",
    "                    self.model1_raw_tokens = float(r1_raw)\n",
    "        \n",
    "                r2_raw = df.at[last_idx, 'Model2_Raw_Tokens']\n",
    "                if pd.notna(r2_raw):\n",
    "                    self.model2_raw_tokens = float(r2_raw)\n",
    "        \n",
    "                r1_b = df.at[last_idx, 'Model1_Batch1_Tokens']\n",
    "                if pd.notna(r1_b):\n",
    "                    self.model1_batch1_tokens = float(r1_b)\n",
    "        \n",
    "                r2_b = df.at[last_idx, 'Model2_Batch2_Tokens']\n",
    "                if pd.notna(r2_b):\n",
    "                    self.model2_batch2_tokens = float(r2_b)\n",
    "        \n",
    "                c_tok = df.at[last_idx, 'Consensus_Tokens']\n",
    "                if pd.notna(c_tok):\n",
    "                    self.consensus_tokens = float(c_tok)\n",
    "                \n",
    "                if self.verbose:\n",
    "                    print(f\"Resuming with cumulative times (seconds):\")\n",
    "                    print(f\"  Model1 batch: {self.model1_batch_time:.1f}\")\n",
    "                    print(f\"  Model2 batch: {self.model2_batch_time:.1f}\")\n",
    "                    print(f\"  Consensus: {self.consensus_time:.1f}\")\n",
    "                    print(f\"  Total: {self.total_processing_time:.1f}\")\n",
    "            else:\n",
    "                # Initialize time tracking variables\n",
    "                self.model1_batch_time = 0\n",
    "                self.model2_batch_time = 0\n",
    "                self.consensus_time = 0\n",
    "                self.total_processing_time = 0\n",
    "        else:\n",
    "            # Initialize time tracking variables\n",
    "            self.model1_batch_time = 0\n",
    "            self.model2_batch_time = 0\n",
    "            self.consensus_time = 0\n",
    "            self.total_processing_time = 0\n",
    "\n",
    "\n",
    "        if test:\n",
    "            df = df.head(10)\n",
    "            if self.verbose:\n",
    "                print(df)\n",
    "        \n",
    "        # Store original columns for reference\n",
    "        self.original_columns = [\n",
    "            col for col in df.columns\n",
    "            if not col.startswith(('Model1_', 'Model2_', 'Consensus_', 'Repair', 'Final_', 'Required_'))\n",
    "        ]\n",
    "    \n",
    "        # -----------------------------------------------------------------\n",
    "        # 2. Ensure required columns exist and define z3 functions and variables\n",
    "        # -----------------------------------------------------------------\n",
    "        needed_columns = COLUMN_NAMES + ['Consensus_Equation'] + ['Model1_raw_list_of_equations', 'Model2_raw_list_of_equations'] + MODEL_ERROR_COLUMNS + TIME_TRACKING_COLUMNS + TOKEN_TRACKING_COLUMNS\n",
    "        for col in needed_columns:\n",
    "            if col not in df.columns:\n",
    "                df[col] = None\n",
    "\n",
    "        Z3_VAR_DICT_EXTENDED = {\n",
    "            var_name: z3.Real(var_name) for var_name in EXPECTED_VARIABLES_EXTENDED\n",
    "        }\n",
    "        \n",
    "        # -----------------------------------------------------------------\n",
    "        # 3. Batch 1: Call Model1 for all rows that need it\n",
    "        # -----------------------------------------------------------------\n",
    "        for idx, row in df.iterrows():\n",
    "            start_time = time.time()\n",
    "            model1_cache = self.load_or_create_cache(self.model_ids[0])\n",
    "            print(f\"Model1 processing for row {idx}\")\n",
    "            student_answer = str(row[self.original_columns[0]])\n",
    "            \n",
    "            if pd.isna(row['Model1_list_of_equations']) or row['Model1_list_of_equations'] in ('', 'Error in Extraction.'):\n",
    "                if not student_answer.strip() or student_answer.strip() == '-':\n",
    "                    # Handle blank answers\n",
    "                    response1 = Default_Response\n",
    "                    df.at[idx, 'Model1_raw_list_of_equations'] = f'[{self.extract_bracket_content(self.extract_sections(response1)[\"list_of_equations\"])}]'\n",
    "                    raw_elapsed = time.time() - start_time\n",
    "                    self.model1_raw_time += raw_elapsed\n",
    "                    self.model1_raw_tokens += 0\n",
    "                    self.model1_batch1_tokens += 0\n",
    "                    df.at[idx, 'Model1_Raw_Tokens'] = self.model1_raw_tokens\n",
    "                    df.at[idx, 'Model1_Raw_Time'] = self.model1_raw_time\n",
    "                    df.at[idx, 'Model1_Batch1_Tokens'] =  self.model1_batch1_tokens\n",
    "                    self.store_extracted_sections_in_df(df, idx, \"Model1\", response1)\n",
    "                else:\n",
    "                    if student_answer in model1_cache:\n",
    "                        if self.verbose:\n",
    "                            print(f\"Cache hit for Model1, row {idx}\")\n",
    "                        cached_data = model1_cache[student_answer]\n",
    "                        \n",
    "                        # Store the raw response\n",
    "                        response1 = cached_data['raw_response']\n",
    "                        df.at[idx, 'Model1_raw_list_of_equations'] = f'[{self.extract_bracket_content(self.extract_sections(response1)[\"list_of_equations\"])}]'\n",
    "                        self.model1_raw_tokens += 0\n",
    "                        self.model1_batch1_tokens += 0\n",
    "                        df.at[idx, 'Model1_Raw_Tokens'] = self.model1_raw_tokens\n",
    "                        df.at[idx, 'Model1_Batch1_Tokens'] =  self.model1_batch1_tokens\n",
    "                        raw_elapsed = time.time() - start_time\n",
    "                        self.model1_raw_time += raw_elapsed\n",
    "                        df.at[idx, 'Model1_Raw_Time'] = self.model1_raw_time\n",
    "                        self.store_extracted_sections_in_df(df, idx, \"Model1\", response1)\n",
    "                        \n",
    "                        # Store the final equations after repair\n",
    "                        if 'final_equations' in cached_data:\n",
    "                            df.at[idx, 'Model1_list_of_equations'] = cached_data['final_equations']\n",
    "                    \n",
    "                    else:\n",
    "                        # Get initial response from Model1\n",
    "                        prompt = self.build_initial_prompt(student_answer)\n",
    "                        response1, raw_tokens = self.get_llm_response(self.model_ids[0], prompt)\n",
    "                        self.model1_raw_tokens += raw_tokens\n",
    "                        self.model1_batch1_tokens += raw_tokens\n",
    "                        df.at[idx, 'Model1_Batch1_Tokens'] = self.model1_batch1_tokens\n",
    "                        df.at[idx, 'Model1_Raw_Tokens'] = self.model1_raw_tokens\n",
    "                        #print(f\"{response1=}\")\n",
    "                        df.at[idx, 'Model1_raw_list_of_equations'] = f'[{self.extract_bracket_content(self.extract_sections(response1)[\"list_of_equations\"])}]'\n",
    "                        self.store_extracted_sections_in_df(df, idx, \"Model1\", response1)\n",
    "                        raw_elapsed = time.time() - start_time\n",
    "                        \n",
    "                        self.model1_raw_time += raw_elapsed\n",
    "                        df.at[idx, 'Model1_Raw_Time'] = self.model1_raw_time\n",
    "                        \n",
    "                        # Attempt parsing and repair if needed\n",
    "                        equations_str = df.at[idx, 'Model1_list_of_equations']\n",
    "                        final_eq1, parsed1 = self.attempt_parse_and_repair(\n",
    "                            equations_str, student_answer, self.model_ids[0], df, idx, \"Model1\"\n",
    "                        ) ###Step 1 - Initiating Repair\n",
    "\n",
    "                        model1_cache[student_answer] = {\n",
    "                            'raw_response': response1,\n",
    "                            'final_equations': df.at[idx, 'Model1_list_of_equations'],\n",
    "                        }\n",
    "                        \n",
    "                        # Save the updated cache\n",
    "                        self.save_cache(model1_cache, self.model_ids[0])\n",
    "\n",
    "                # Record time and save\n",
    "                elapsed = time.time() - start_time\n",
    "                self.model1_batch_time += elapsed\n",
    "                self.total_processing_time += elapsed\n",
    "                df.at[idx, 'Model1_Batch1_Tokens'] = self.model1_batch1_tokens\n",
    "                df.at[idx, 'Model1_Batch1_Fails'] = self.model1_fails\n",
    "                df.at[idx, 'Model1_Batch1_Time'] = self.model1_batch_time\n",
    "                df.at[idx, 'Total_Processing_Time'] = self.total_processing_time\n",
    "                df.to_csv(PROCESSED_FILE, sep='\\t', index=False, encoding='utf-8')\n",
    "        \n",
    "        # -----------------------------------------------------------------\n",
    "        # 4. Batch 2: Call Model2 for all rows that need it\n",
    "        # -----------------------------------------------------------------\n",
    "        for idx, row in df.iterrows():\n",
    "            start_time = time.time()\n",
    "            # Load cache for this iteration\n",
    "            model2_cache = self.load_or_create_cache(self.model_ids[1])\n",
    "            \n",
    "            print(f\"Model2 processing for row {idx}\")\n",
    "            student_answer = str(row[self.original_columns[0]])\n",
    "            \n",
    "            if pd.isna(row['Model2_list_of_equations']) or row['Model2_list_of_equations'] in ('', 'Error in Extraction.'):\n",
    "                if not student_answer.strip() or student_answer.strip() == '-':\n",
    "                    # Handle blank answers\n",
    "                    response2 = Default_Response\n",
    "                    df.at[idx, 'Model2_raw_list_of_equations'] = f'[{self.extract_bracket_content(self.extract_sections(response2)[\"list_of_equations\"])}]'\n",
    "                    raw_elapsed = time.time() - start_time\n",
    "                    self.model2_raw_time += raw_elapsed\n",
    "                    self.model2_raw_tokens += 0\n",
    "                    self.model2_batch2_tokens += 0\n",
    "                    df.at[idx, 'Model2_Raw_Tokens'] = self.model2_raw_tokens\n",
    "                    df.at[idx, 'Model2_Raw_Time'] = self.model2_raw_time\n",
    "                    df.at[idx, 'Model2_Batch2_Tokens'] =  self.model2_batch2_tokens\n",
    "                    self.store_extracted_sections_in_df(df, idx, \"Model2\", response2)\n",
    "                else:\n",
    "                    if student_answer in model2_cache:\n",
    "                        if self.verbose:\n",
    "                            print(f\"Cache hit for Model2, row {idx}\")\n",
    "                        cached_data = model2_cache[student_answer]\n",
    "                        \n",
    "                        # Store the raw response\n",
    "                        response2 = cached_data['raw_response']\n",
    "                        df.at[idx, 'Model2_raw_list_of_equations'] = f'[{self.extract_bracket_content(self.extract_sections(response2)[\"list_of_equations\"])}]'\n",
    "                        self.model2_raw_tokens += 0\n",
    "                        self.model2_batch2_tokens += 0\n",
    "                        df.at[idx, 'Model2_Raw_Tokens'] = self.model2_raw_tokens\n",
    "                        raw_elapsed = time.time() - start_time\n",
    "                        self.model2_raw_time += raw_elapsed\n",
    "                        df.at[idx, 'Model2_Raw_Time'] = self.model2_raw_time\n",
    "                        df.at[idx, 'Model2_Batch2_Tokens'] =  self.model2_batch2_tokens\n",
    "                        self.store_extracted_sections_in_df(df, idx, \"Model2\", response2)\n",
    "                        \n",
    "                        # Store the final equations after repair\n",
    "                        if 'final_equations' in cached_data:\n",
    "                            df.at[idx, 'Model2_list_of_equations'] = cached_data['final_equations']\n",
    "                    \n",
    "                    else:\n",
    "                        # Get initial response from Model2\n",
    "                        prompt = self.build_initial_prompt(student_answer)\n",
    "                        response2, raw_tokens = self.get_llm_response(self.model_ids[1], prompt)\n",
    "                        self.model2_raw_tokens += raw_tokens\n",
    "                        self.model2_batch2_tokens += raw_tokens\n",
    "                        df.at[idx, 'Model2_Raw_Tokens'] = self.model2_raw_tokens\n",
    "                        df.at[idx, 'Model2_Batch2_Tokens'] = self.model2_batch2_tokens\n",
    "                        #print(f\"{response2=}\")\n",
    "                        df.at[idx, 'Model2_raw_list_of_equations'] = f'[{self.extract_bracket_content(self.extract_sections(response2)[\"list_of_equations\"])}]'\n",
    "                        self.store_extracted_sections_in_df(df, idx, \"Model2\", response2)\n",
    "                        raw_elapsed = time.time() - start_time\n",
    "                        \n",
    "                        self.model2_raw_time += raw_elapsed\n",
    "                        df.at[idx, 'Model2_Raw_Time'] = self.model2_raw_time\n",
    "                        \n",
    "                        # Attempt parsing and repair if needed\n",
    "                        equations_str = df.at[idx, 'Model2_list_of_equations']\n",
    "                        final_eq2, parsed2 = self.attempt_parse_and_repair(\n",
    "                            equations_str, student_answer, self.model_ids[1], df, idx, \"Model2\"\n",
    "                        )\n",
    "        \n",
    "                        model2_cache[student_answer] = {\n",
    "                            'raw_response': response2,\n",
    "                            'final_equations': df.at[idx, 'Model2_list_of_equations'],\n",
    "                        }\n",
    "                \n",
    "                        # Save the updated cache\n",
    "                        self.save_cache(model2_cache, self.model_ids[1])\n",
    "        \n",
    "                # Record time and save\n",
    "                elapsed = time.time() - start_time\n",
    "                self.model2_batch_time += elapsed\n",
    "                self.total_processing_time += elapsed\n",
    "                df.at[idx, 'Model2_Batch2_Tokens'] = self.model2_batch2_tokens\n",
    "                df.at[idx, 'Model2_Batch2_Fails'] = self.model2_fails\n",
    "                df.at[idx, 'Model2_Batch2_Time'] = self.model2_batch_time\n",
    "                df.at[idx, 'Total_Processing_Time'] = self.total_processing_time\n",
    "                df.to_csv(PROCESSED_FILE, sep='\\t', index=False, encoding='utf-8')\n",
    "        \n",
    "        # -----------------------------------------------------------------\n",
    "        # 5. Check for matches and attempt consensus where needed\n",
    "        # -----------------------------------------------------------------\n",
    "        if do_consensus:\n",
    "            for idx, row in df.iterrows():\n",
    "                start_time = time.time()\n",
    "    \n",
    "                consensus_cache_filename = f\"consensus_cache_{sanitize_filename(self.model_ids[0])}_{sanitize_filename(self.model_ids[1])}.json\"\n",
    "                consensus_cache = self.load_consensus_cache(consensus_cache_filename)\n",
    "                \n",
    "                print(f\"Consensus processing for row {idx}\")\n",
    "                student_answer = str(row[self.original_columns[0]])\n",
    "    \n",
    "                if pd.notna(row['Consensus_Equation']) and row['Consensus_Equation'] not in ('', 'Error in Extraction.'):\n",
    "                    print(f\"  Skipping row {idx} - consensus already exists\")\n",
    "                    continue\n",
    "                    \n",
    "                eq1 = row['Model1_list_of_equations'] or \"\"\n",
    "                eq2 = row['Model2_list_of_equations'] or \"\"\n",
    "        \n",
    "                # Handle empty equations\n",
    "                if not eq1.strip('[]') and not eq2.strip('[]'):\n",
    "                    df.at[idx, 'Consensus_Equation'] = '[]'\n",
    "                    elapsed = time.time() - start_time\n",
    "                    self.consensus_time += elapsed\n",
    "                    self.total_processing_time += elapsed\n",
    "                    df.at[idx, 'Consensus_Time'] = self.consensus_time \n",
    "                    df.at[idx, 'Total_Processing_Time'] = self.total_processing_time\n",
    "                    df.at[idx, 'Model1_Consensus_Fails'] = self.model1_fails\n",
    "                    df.at[idx, 'Model2_Consensus_Fails'] = self.model2_fails\n",
    "                    df.at[idx, 'Consensus_Tokens'] = self.consensus_tokens\n",
    "                    df.to_csv(PROCESSED_FILE, sep='\\t', index=False, encoding='utf-8')\n",
    "                    continue\n",
    "        \n",
    "    \n",
    "                cache_key = f\"{student_answer}\"\n",
    "                \n",
    "                if cache_key in consensus_cache:\n",
    "                    print(f\"  Consensus cache hit for row {idx}\")\n",
    "                    df.at[idx, 'Consensus_Equation'] = consensus_cache[cache_key]\n",
    "                else:\n",
    "                    # Try to reach consensus\n",
    "                    consensus_equation = self.reach_consensus(student_answer, eq1, eq2, df, idx)\n",
    "                    df.at[idx, 'Consensus_Equation'] = consensus_equation\n",
    "                    \n",
    "                    # Add to cache\n",
    "                    consensus_cache[cache_key] = consensus_equation\n",
    "                    self.save_consensus_cache(consensus_cache, consensus_cache_filename)\n",
    "    \n",
    "                # Record time and save\n",
    "                elapsed = time.time() - start_time\n",
    "                self.consensus_time += elapsed\n",
    "                self.total_processing_time += elapsed\n",
    "                df.at[idx, 'Consensus_Time'] = self.consensus_time \n",
    "                df.at[idx, 'Total_Processing_Time'] = self.total_processing_time\n",
    "                df.at[idx, 'Model1_Consensus_Fails'] = self.model1_fails\n",
    "                df.at[idx, 'Model2_Consensus_Fails'] = self.model2_fails\n",
    "                df.at[idx, 'Consensus_Tokens'] = self.consensus_tokens\n",
    "        \n",
    "                # Save progress\n",
    "                df.to_csv(PROCESSED_FILE, sep='\\t', index=False, encoding='utf-8')\n",
    "    \n",
    "        # -----------------------------------------------------------------\n",
    "        # 6. Final summary\n",
    "        # -----------------------------------------------------------------\n",
    "        if True: #self.verbose:\n",
    "            total_rows = len(df)\n",
    "            consensus_reached = df['Consensus_Equation'].notna().sum()\n",
    "            print(\"\\n\" + \"=\"*50)\n",
    "            print(\"BATCH PROCESSING SUMMARY\")\n",
    "            print(\"=\"*50)\n",
    "            print(f\"Total rows: {total_rows}\")\n",
    "            print(f\"Consensus reached: {consensus_reached}\")\n",
    "            print(f\"Model1 fails: {self.model1_fails}\")\n",
    "            print(f\"Model2 fails: {self.model2_fails}\")\n",
    "            print(f\"Time elapsed (seconds):\")\n",
    "            print(f\"  Model1 batch: {self.model1_batch_time:.1f}\")\n",
    "            print(f\"  Model2 batch: {self.model2_batch_time:.1f}\")\n",
    "            print(f\"  Consensus: {self.consensus_time:.1f}\")\n",
    "            print(f\"  Total: {self.total_processing_time:.1f}\")\n",
    "            print(f\"  Average per row: {self.total_processing_time/total_rows:.1f}\")\n",
    "            print(\"=\"*50)\n",
    "        \n",
    "        return df, self.model1_fails, self.model2_fails\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb0159d-5cd6-42bf-aa68-2b1a75e2c27b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172d9d2b-9208-48a0-8308-29346be5ff10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the validator\n",
    "validator = LLMResponseValidator(max_repair_attempts=3, verbose=False)\n",
    "\n",
    "print(f\"Processing file: {ORIGINAL_FILE}\")\n",
    "print(f\"Results will be saved to: {PROCESSED_FILE}\")\n",
    "\n",
    "# Call the new batch method\n",
    "processed_df, model1fails, model2fails = validator.process_dataframe_in_batches(test = False, do_consensus = False)\n",
    "\n",
    "print(\"\\nProcessing complete!\")\n",
    "print(f\"Total rows processed: {len(processed_df)}\")\n",
    "\n",
    "# Print final statistics\n",
    "print(\"\\nFinal Statistics:\")\n",
    "#print(f\"Total rows needing repair: {processed_df['RepairNeeded'].sum()}\")\n",
    "\n",
    "# Display first few rows of the processed dataframe\n",
    "print(\"\\nFirst few rows of processed data:\")\n",
    "display(processed_df.head())  # or just 'print(processed_df.head())'\n",
    "print(f\"{model1fails=}\")\n",
    "print(f\"{model2fails=}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5455c849-2809-4659-a583-40349343cbfb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d56d43a0-c6a4-4135-a20f-52481c93629d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f94091-33fb-4189-b143-77bb4b85428f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d911c43-f333-4336-8a49-bd0ea4d35f08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b152aad2-2250-477f-92a9-f38e9538867c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82c824f-88fb-489f-a17d-c36d21e5124c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b11a48-c7bb-4023-a3b0-4bb3502c16ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6982fc02-219e-4a5c-bdfb-6a217301b4dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd420d68-f85a-4a0b-982c-cc591327e441",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831f5974-555a-4020-abc5-cf2c992262ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91bb5c27-686a-45fb-a034-48c5939b1092",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e7c254-9ea1-4449-b312-44af6951e388",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edcad009-9441-4fd6-b29f-9bfcaa972ef3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af161e5b-3376-4c38-8299-fe72cb29e421",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617ab03e-b801-4c09-a90e-18d1e8fe5343",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
